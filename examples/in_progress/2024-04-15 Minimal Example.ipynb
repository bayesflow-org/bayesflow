{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Backend-Agnostic Two Moons\n",
    "\n",
    "This example notebook covers a backend-agnostic model trained online on the two moons dataset. You will learn how to:\n",
    "\n",
    "1. Use BayesFlow with your backend of choice\n",
    "2. Define joint distributions with BayesFlow decorators\n",
    "3. Fit an amortized posterior with the new BayesFlow interface"
   ],
   "id": "9d4eaec8f5ddbdac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Select a Backend\n",
    "\n",
    "You can select a backend by setting the KERAS_BACKEND environment variable to one of \"jax\", \"tensorflow\", or \"torch\". You can do this by running any of the following commands. For this notebook, we set the variable dynamically, so you can switch it around as you like, but in general we recommend the conda environment version.\n",
    "\n",
    "1. Using your system environment variables:\n",
    "```\n",
    "export KERAS_BACKEND=\"torch\"\n",
    "```\n",
    "\n",
    "2. Using conda:\n",
    "```\n",
    "conda env config vars set KERAS_BACKEND=\"torch\"\n",
    "```\n",
    "\n",
    "3. Dynamically in Python:"
   ],
   "id": "6317fc4b0c53afb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:24.144153Z",
     "start_time": "2024-05-10T14:52:24.142145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# \"jax\", \"tensorflow\", or \"torch\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "id": "b8761dfa1aeba0e0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Defining the Simulation\n",
    "\n",
    "We will use online training on the two moons toy dataset in this example. To define a joint distribution, we use convenience decorators:"
   ],
   "id": "28e1b53efbf8b696"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:24.681571Z",
     "start_time": "2024-05-10T14:52:24.678865Z"
    }
   },
   "source": [
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import bayesflow.experimental as bf"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Context Distribution:",
   "id": "2049b1b099ef5125"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:25.146389Z",
     "start_time": "2024-05-10T14:52:25.142284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_context():\n",
    "    # r ~ N(0.1, 0.01)\n",
    "    r = keras.random.normal(shape=(1,), mean=0.1, stddev=0.01)\n",
    "    # alpha ~ U(-π/2, π/2)\n",
    "    alpha = keras.random.uniform(shape=(1,), minval=-0.5 * np.pi, maxval=0.5 * np.pi)\n",
    "    return dict(r=r, alpha=alpha)"
   ],
   "id": "7a7a097d36ca9369",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parameter Prior:",
   "id": "758eb75b64cc07fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:25.487004Z",
     "start_time": "2024-05-10T14:52:25.482352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_prior():\n",
    "    # θ ~ U(-1, 1)\n",
    "    theta = keras.random.uniform(shape=(2,), minval=-1.0, maxval=1.0)\n",
    "    return dict(theta=theta)"
   ],
   "id": "fe1a140bf4fdb5bb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simulator:",
   "id": "97d94f1c83315ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:25.838646Z",
     "start_time": "2024-05-10T14:52:25.832945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_likelihood(r, alpha, theta):\n",
    "    # simulate the two moons\n",
    "    x1 = -keras.ops.abs(theta[0] + theta[1]) / np.sqrt(2.0) + r * keras.ops.cos(alpha) + 0.25\n",
    "    x2 = (-theta[0] + theta[1]) / np.sqrt(2.0) + r * keras.ops.sin(alpha)\n",
    "    return dict(x=keras.ops.concatenate([x1, x2], axis=0))"
   ],
   "id": "f923a53c42eb5870",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Combining these to yield a joint distribution:",
   "id": "b469554f79973f7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:26.167201Z",
     "start_time": "2024-05-10T14:52:26.164611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "joint_distribution = bf.simulation.DefaultJointDistribution(\n",
    "    local_context=two_moons_context,\n",
    "    global_context=None,\n",
    "    prior=two_moons_prior,\n",
    "    likelihood=two_moons_likelihood,\n",
    ")"
   ],
   "id": "13b798ac17b1b4f6",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Defining the training strategy via a Dataset\n",
    "\n",
    "We want to train online, meaning we sample new data for each training step. BayesFlow already provides a Dataset for such common cases:"
   ],
   "id": "f636f653eacc2ca5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:26.489672Z",
     "start_time": "2024-05-10T14:52:26.486589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pass batch size and steps per epoch here for now\n",
    "# support this issue to fix that and move these to posterior.fit()\n",
    "# https://github.com/keras-team/keras/issues/19528\n",
    "train_dataset = bf.datasets.OnlineDataset(\n",
    "    joint_distribution=joint_distribution,\n",
    "    batch_size=64,\n",
    "    workers=8,\n",
    "    # use_multiprocessing=True,\n",
    ")\n",
    "validation_dataset = bf.datasets.OnlineDataset(\n",
    "    joint_distribution=joint_distribution,\n",
    "    batch_size=64,\n",
    "    workers=8,\n",
    "    # use_multiprocessing=True,\n",
    ")"
   ],
   "id": "6c441725aed2cd59",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Defining Summary and Inference Networks\n",
    "\n",
    "We do not want to use a summary network for this example, so we just leave this blank. As the inference network, we use a 4-layer coupling flow with affine transforms."
   ],
   "id": "3e8bb9cd5312c1cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:26.820526Z",
     "start_time": "2024-05-10T14:52:26.816878Z"
    }
   },
   "cell_type": "code",
   "source": "summary_network = None",
   "id": "165130d7a6bde198",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:26.992640Z",
     "start_time": "2024-05-10T14:52:26.988752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define this manually, for now\n",
    "class Subnet(keras.Layer):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.network = keras.Sequential([\n",
    "            keras.layers.Dense(512, activation=\"relu\"),\n",
    "            keras.layers.Dense(2 * out_features),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.network(x)"
   ],
   "id": "bf3218e85f5a2c39",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:27.188008Z",
     "start_time": "2024-05-10T14:52:27.149980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use a sequential coupling flow\n",
    "# method name is subject to change\n",
    "# we will allow to use the default BayesFlow networks in the future\n",
    "inference_network = bf.networks.CouplingFlow.uniform(\n",
    "    subnet_constructor=Subnet,\n",
    "    # 2 parameters\n",
    "    target_dim=2,\n",
    "    num_layers=4,\n",
    "    transform=\"affine\",\n",
    "    base_distribution=\"normal\",\n",
    ")"
   ],
   "id": "5614f8e784c5d114",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Putting Things Together\n",
    "\n",
    "Now that the model internals are defined, collect them in an `AmortizedPosterior` and train."
   ],
   "id": "8fea531279e6d17e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:27.820145Z",
     "start_time": "2024-05-10T14:52:27.815665Z"
    }
   },
   "cell_type": "code",
   "source": "posterior = bf.AmortizedPosterior(inference_network=inference_network, summary_network=summary_network)",
   "id": "21bf882a3bd74d59",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:28.060860Z",
     "start_time": "2024-05-10T14:52:28.056138Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=0.01)",
   "id": "f130a68e9c1e37fa",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:28.272940Z",
     "start_time": "2024-05-10T14:52:28.268528Z"
    }
   },
   "cell_type": "code",
   "source": "posterior.compile(optimizer)",
   "id": "afdf491e94d8a0b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:28.492438Z",
     "start_time": "2024-05-10T14:52:28.489495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    # track losses and metrics in TensorBoard\n",
    "    keras.callbacks.TensorBoard(\"logs/two_moons/\"),\n",
    "    # save the best model each epoch\n",
    "    keras.callbacks.ModelCheckpoint(\"logs/two_moons/checkpoints/model.keras\", save_best_only=True)\n",
    "]"
   ],
   "id": "3ac5a9b644ddfd0e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, fit your model:",
   "id": "f0bb22b1dba281e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:52:29.733006Z",
     "start_time": "2024-05-10T14:52:29.588901Z"
    }
   },
   "cell_type": "code",
   "source": "posterior.fit(train_dataset, validation_data=validation_dataset, epochs=100, callbacks=callbacks)",
   "id": "9f68ac236137659f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_6650/1252914424.py\", line 1, in <module>\n",
      "    posterior.fit(train_dataset, validation_data=validation_dataset, epochs=100, callbacks=callbacks)\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 41, in fetch\n",
      "    data = next(self.dataset_iter)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/multiprocessing/pool.py\", line 774, in get\n",
      "    raise self._value\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/lars/Documents/code/python/bayesflow/bayesflow/experimental/datasets/online_dataset.py\", line 18, in __getitem__\n",
      "    data = self.joint_distribution.sample((self.batch_size,))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/Documents/code/python/bayesflow/bayesflow/experimental/simulation/distributions/joint_distribution/default_joint_distribution.py\", line 28, in sample\n",
      "    local_context = self.local_context.sample(batch_shape, *args)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/Documents/code/python/bayesflow/bayesflow/experimental/simulation/decorators/distribution_decorator.py\", line 75, in sample\n",
      "    return batched_sample_fn(batch_shape, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/Documents/code/python/bayesflow/bayesflow/experimental/simulation/decorators/distribution_decorator.py\", line 53, in batched_sample_fn\n",
      "    samples = keras.ops.vectorized_map(f, (dummy_argument, *args))\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/_functorch/apis.py\", line 188, in wrapped\n",
      "    return vmap_impl(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/_functorch/vmap.py\", line 278, in vmap_impl\n",
      "    return _flat_vmap(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/_functorch/vmap.py\", line 44, in fn\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/torch/_functorch/vmap.py\", line 394, in _flat_vmap\n",
      "    _vmap_decrement_nesting()\n",
      "  File \"/home/lars/Documents/code/python/bayesflow/bayesflow/experimental/simulation/decorators/distribution_decorator.py\", line 47, in f\n",
      "    return sample_fn(*tensors[1:])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6650/200458136.py\", line 4, in two_moons_context\n",
      "    r = keras.random.normal(shape=(1,), mean=0.1, stddev=0.01)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: vmap: called random operation while in randomness error mode. Please either use the 'same' or 'different' randomness flags on vmap or perform the randomness operation out of vmap\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/stack_data/utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/stack_data/core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/stack_data/core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/executing/executing.py\", line 283, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "  File \"/home/lars/miniforge3/envs/keras-torch/lib/python3.11/site-packages/executing/executing.py\", line 80, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bf.diagnostics.show_posterior(posterior=posterior)",
   "id": "c4ae70791163ac91",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
