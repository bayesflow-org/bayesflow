{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "from numba import njit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.networks import EvidentialNetwork\n",
    "from bayesflow.trainers import MultiModelTrainer\n",
    "from bayesflow.losses import log_loss\n",
    "from bayesflow.diagnostics import plot_confusion_matrix, plot_calibration_curves, expected_calibration_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example simulation-based model comparison workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prior\n",
    "Implements sampling from $p(\\mathcal{M})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_prior(batch_size, p_vals=None):\n",
    "    \"\"\"\n",
    "    Samples from the models' prior batch size times and converts to one-hot.\n",
    "    Assumes equal model priors.\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size : int  -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "    \n",
    "    Returns:\n",
    "    m_true : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Equal priors, if nothign specified\n",
    "    if p_vals is None:\n",
    "        p_vals = [1/3] * 3\n",
    "    m_idx = np.random.choice(3, size=batch_size, p=p_vals).astype(np.int32)\n",
    "    return m_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter priors\n",
    "Implements sampling from each $p(\\theta_j\\,|\\,\\mathcal{M}_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     20,
     41
    ]
   },
   "outputs": [],
   "source": [
    "def model1_params_prior(**args):\n",
    "    \"\"\"\n",
    "    Samples from the prior of the HH-2pars theta = (gbar_Na,gbar_K)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "         np.random.uniform(low=1.5, high=30), \n",
    "         np.random.uniform(low=0.3, high=15)\n",
    "    ]\n",
    "    return np.array(theta)\n",
    "\n",
    "\n",
    "def model2_params_prior(**args):\n",
    "    \"\"\"\n",
    "     Samples from the prior of the HH-3pars theta = (gbar_Na,gbar_K,gbar_M)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "        np.random.uniform(low=1.5, high=30), \n",
    "        np.random.uniform(low=0.3, high=15),\n",
    "        np.random.uniform(low=0.005, high=0.3)  \n",
    "    ]\n",
    "    return np.array(theta)\n",
    "\n",
    "\n",
    "def model3_params_prior(**args):\n",
    "    \"\"\"\n",
    "    Samples from the prior of the HH-4pars theta = (gbar_l,gbar_Na,gbar_K,gbar_M)\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    \n",
    "    Output:\n",
    "    theta : np.ndarray of shape (1, theta_dim) -- the samples of parameters\n",
    "            or a dict with param key-values\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = [\n",
    "        np.random.uniform(low=0.01, high=0.18),\n",
    "        np.random.uniform(low=1.5, high=30), \n",
    "        np.random.uniform(low=0.1, high=15),\n",
    "        np.random.uniform(low=0.005, high=0.3)\n",
    "    ]\n",
    "    return np.array(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulators\n",
    "Implements each forward model (stochastic simulator) $g_j(\\theta_j,\\xi)$. Uses $numba$ for just-in-time compilation (i.e., speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def forward_model1(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    \n",
    "    # HH-2pars    \n",
    "\n",
    "    # pars = [gbar_Na, gbar_K]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "    \n",
    "    I_duration = n_obs\n",
    "    gbar_Na, gbar_K = params\n",
    "\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2   # ms\n",
    "    Vt = -60.       # mV\n",
    "    nois_fact = 0.1 # uA/cm2\n",
    "    E_leak = -70.   # mV\n",
    "    E_Na = 53       # mV\n",
    "    E_K = -107      # mV\n",
    "    C = 1\n",
    "    g_l = 0.1\n",
    "    gbar_M = 0.07\n",
    "\n",
    "    tstep = float(dt)\n",
    "    \n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_off = I_duration + 10\n",
    "    t = np.arange(0, t_on+t_off+dt, dt)\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on/dt)):int(np.round(t_off/dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z/2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32*efun(-0.25*v1)/0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28*efun(0.2*v1)/0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128*np.exp(-v1/18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0/(1 + np.exp(-0.2*v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032*efun(-0.2*v1)/0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5*np.exp(-v1/40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "         return 1/(alpha_n(x) + beta_n(x))\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x)/(alpha_n(x) + beta_n(x))\n",
    "    def tau_m(x):\n",
    "        return 1/(alpha_m(x) + beta_m(x))\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x)/(alpha_m(x) + beta_m(x))\n",
    "    def tau_h(x):\n",
    "        return 1/(alpha_h(x) + beta_h(x))\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x)/(alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0/(1. + np.exp(-0.1*v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max/(3.3*np.exp(0.05*v1) + np.exp(-0.05*v1))\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t) # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ( (m[i-1]**3)*gbar_Na*h[i-1]+(n[i-1]**4)*gbar_K+g_l+gbar_M*p[i-1] )/C\n",
    "        V_inf = ( (m[i-1]**3)*gbar_Na*h[i-1]*E_Na+(n[i-1]**4)*gbar_K*E_K+g_l*E_leak+gbar_M*p[i-1]*E_K\n",
    "                +I[i-1]+nois_fact*np.random.randn()/(tstep**0.5) )/(tau_V_inv*C)\n",
    "        V[i] = V_inf + (V[i-1]-V_inf)*np.exp(-tstep*tau_V_inv)\n",
    "        n[i] = n_inf(V[i])+(n[i-1]-n_inf(V[i]))*np.exp(-tstep/tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i])+(m[i-1]-m_inf(V[i]))*np.exp(-tstep/tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i])+(h[i-1]-h_inf(V[i]))*np.exp(-tstep/tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i])+(p[i-1]-p_inf(V[i]))*np.exp(-tstep/tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)\n",
    "\n",
    "\n",
    "@njit\n",
    "def forward_model2(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    \n",
    "    # HH-3pars    \n",
    "\n",
    "    # pars = [gbar_Na, gbar_K, gbar_M]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "    \n",
    "    I_duration = n_obs\n",
    "    gbar_Na, gbar_K, gbar_M = params\n",
    "\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2   # ms\n",
    "    Vt = -60.       # mV\n",
    "    nois_fact = 0.1 # uA/cm2\n",
    "    E_leak = -70.   # mV\n",
    "    E_Na = 53       # mV\n",
    "    E_K = -107      # mV\n",
    "    C = 1\n",
    "    g_l = 0.1\n",
    "\n",
    "    tstep = float(dt)\n",
    "    \n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_off = I_duration + 10\n",
    "    t = np.arange(0, t_on+t_off+dt, dt)\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on/dt)):int(np.round(t_off/dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z/2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32*efun(-0.25*v1)/0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28*efun(0.2*v1)/0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128*np.exp(-v1/18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0/(1 + np.exp(-0.2*v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032*efun(-0.2*v1)/0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5*np.exp(-v1/40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "         return 1/(alpha_n(x) + beta_n(x))\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x)/(alpha_n(x) + beta_n(x))\n",
    "    def tau_m(x):\n",
    "        return 1/(alpha_m(x) + beta_m(x))\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x)/(alpha_m(x) + beta_m(x))\n",
    "    def tau_h(x):\n",
    "        return 1/(alpha_h(x) + beta_h(x))\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x)/(alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0/(1. + np.exp(-0.1*v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max/(3.3*np.exp(0.05*v1) + np.exp(-0.05*v1))\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t) # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ( (m[i-1]**3)*gbar_Na*h[i-1]+(n[i-1]**4)*gbar_K+g_l+gbar_M*p[i-1] )/C\n",
    "        V_inf = ( (m[i-1]**3)*gbar_Na*h[i-1]*E_Na+(n[i-1]**4)*gbar_K*E_K+g_l*E_leak+gbar_M*p[i-1]*E_K\n",
    "                +I[i-1]+nois_fact*np.random.randn()/(tstep**0.5) )/(tau_V_inv*C)\n",
    "        V[i] = V_inf + (V[i-1]-V_inf)*np.exp(-tstep*tau_V_inv)\n",
    "        n[i] = n_inf(V[i])+(n[i-1]-n_inf(V[i]))*np.exp(-tstep/tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i])+(m[i-1]-m_inf(V[i]))*np.exp(-tstep/tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i])+(h[i-1]-h_inf(V[i]))*np.exp(-tstep/tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i])+(p[i-1]-p_inf(V[i]))*np.exp(-tstep/tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)\n",
    "\n",
    "\n",
    "@njit\n",
    "def forward_model3(params, n_obs, V0=-70, I_input=3, dt=0.2):\n",
    "    \n",
    "    # HH-4pars    \n",
    "\n",
    "    # pars = [gbar_l, gbar_Na, gbar_K, gbar_M]\n",
    "    # I_input = input current in muA/cm2\n",
    "    # I_duration = duration of current input in ms\n",
    "    # dt = dt\n",
    "    \n",
    "    I_duration = n_obs\n",
    "    g_l, gbar_Na, gbar_K, gbar_M = params\n",
    "\n",
    "\n",
    "    # fixed parameters\n",
    "    tau_max = 6e2   # ms\n",
    "    Vt = -60.       # mV\n",
    "    nois_fact = 0.1 # uA/cm2\n",
    "    E_leak = -70.   # mV\n",
    "    E_Na = 53       # mV\n",
    "    E_K = -107      # mV\n",
    "    C = 1\n",
    "\n",
    "    tstep = float(dt)\n",
    "    \n",
    "    ####################################\n",
    "    # Current (I) muA/cm2\n",
    "    t_on = 10\n",
    "    t_off = I_duration + 10\n",
    "    t = np.arange(0, t_on+t_off+dt, dt)\n",
    "    I = np.zeros_like(t)\n",
    "    I[int(np.round(t_on/dt)):int(np.round(t_off/dt))] = I_input\n",
    "\n",
    "    ####################################\n",
    "    # kinetics\n",
    "    def efun(z):\n",
    "        if np.abs(z) < 1e-4:\n",
    "            return 1 - z/2\n",
    "        else:\n",
    "            return z / (np.exp(z) - 1)\n",
    "\n",
    "    def alpha_m(x):\n",
    "        v1 = x - Vt - 13.\n",
    "        return 0.32*efun(-0.25*v1)/0.25\n",
    "\n",
    "    def beta_m(x):\n",
    "        v1 = x - Vt - 40\n",
    "        return 0.28*efun(0.2*v1)/0.2\n",
    "\n",
    "    def alpha_h(x):\n",
    "        v1 = x - Vt - 17.\n",
    "        return 0.128*np.exp(-v1/18.)\n",
    "\n",
    "    def beta_h(x):\n",
    "        v1 = x - Vt - 40.\n",
    "        return 4.0/(1 + np.exp(-0.2*v1))\n",
    "\n",
    "    def alpha_n(x):\n",
    "        v1 = x - Vt - 15.\n",
    "        return 0.032*efun(-0.2*v1)/0.2\n",
    "\n",
    "    def beta_n(x):\n",
    "        v1 = x - Vt - 10.\n",
    "        return 0.5*np.exp(-v1/40)\n",
    "\n",
    "    # steady-states and time constants\n",
    "    def tau_n(x):\n",
    "         return 1/(alpha_n(x) + beta_n(x))\n",
    "    def n_inf(x):\n",
    "        return alpha_n(x)/(alpha_n(x) + beta_n(x))\n",
    "    def tau_m(x):\n",
    "        return 1/(alpha_m(x) + beta_m(x))\n",
    "    def m_inf(x):\n",
    "        return alpha_m(x)/(alpha_m(x) + beta_m(x))\n",
    "    def tau_h(x):\n",
    "        return 1/(alpha_h(x) + beta_h(x))\n",
    "    def h_inf(x):\n",
    "        return alpha_h(x)/(alpha_h(x) + beta_h(x))\n",
    "\n",
    "    # slow non-inactivating K+\n",
    "    def p_inf(x):\n",
    "        v1 = x + 35.\n",
    "        return 1.0/(1. + np.exp(-0.1*v1))\n",
    "\n",
    "    def tau_p(x):\n",
    "        v1 = x + 35.\n",
    "        return tau_max/(3.3*np.exp(0.05*v1) + np.exp(-0.05*v1))\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    # simulation from initial point\n",
    "    V = np.zeros_like(t) # voltage\n",
    "    n = np.zeros_like(t)\n",
    "    m = np.zeros_like(t)\n",
    "    h = np.zeros_like(t)\n",
    "    p = np.zeros_like(t)\n",
    "\n",
    "    V[0] = float(V0)\n",
    "    n[0] = n_inf(V[0])\n",
    "    m[0] = m_inf(V[0])\n",
    "    h[0] = h_inf(V[0])\n",
    "    p[0] = p_inf(V[0])\n",
    "\n",
    "    for i in range(1, t.shape[0]):\n",
    "        tau_V_inv = ( (m[i-1]**3)*gbar_Na*h[i-1]+(n[i-1]**4)*gbar_K+g_l+gbar_M*p[i-1] )/C\n",
    "        V_inf = ( (m[i-1]**3)*gbar_Na*h[i-1]*E_Na+(n[i-1]**4)*gbar_K*E_K+g_l*E_leak+gbar_M*p[i-1]*E_K\n",
    "                +I[i-1]+nois_fact*np.random.randn()/(tstep**0.5) )/(tau_V_inv*C)\n",
    "        V[i] = V_inf + (V[i-1]-V_inf)*np.exp(-tstep*tau_V_inv)\n",
    "        n[i] = n_inf(V[i])+(n[i-1]-n_inf(V[i]))*np.exp(-tstep/tau_n(V[i]))\n",
    "        m[i] = m_inf(V[i])+(m[i-1]-m_inf(V[i]))*np.exp(-tstep/tau_m(V[i]))\n",
    "        h[i] = h_inf(V[i])+(h[i-1]-h_inf(V[i]))*np.exp(-tstep/tau_h(V[i]))\n",
    "        p[i] = p_inf(V[i])+(p[i-1]-p_inf(V[i]))*np.exp(-tstep/tau_p(V[i]))\n",
    "\n",
    "    return np.expand_dims(V, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example amortized model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add stuff here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an amortized estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceNet(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creates a custom summary network, a combination of 1D conv and LSTM.\n",
    "        \"\"\"\n",
    "        super(SequenceNet, self).__init__()\n",
    "        \n",
    "        self.conv_part = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(64, 3, 3, activation='elu'),\n",
    "            tf.keras.layers.Conv1D(64, 3, 3, activation='elu'),\n",
    "            tf.keras.layers.Conv1D(64, 3, 3, activation='elu'),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.lstm_part = Sequential(\n",
    "            [LSTM(32, return_sequences=True), \n",
    "             LSTM(64)\n",
    "            ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"Performs a forward pass.\"\"\"\n",
    "        \n",
    "        conv_out = self.conv_part(x)\n",
    "        lstm_out = self.lstm_part(x)\n",
    "        out = tf.concat((conv_out, lstm_out), axis=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = SequenceNet()\n",
    "\n",
    "evidential_meta = {\n",
    "    'n_models': 3,\n",
    "    'out_activation': 'softplus',\n",
    "    'n_dense': 3,\n",
    "    'dense_args': {'kernel_initializer': 'glorot_uniform', 'activation': 'relu', 'units': 128}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidential_net = EvidentialNetwork(evidential_meta, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [model1_params_prior, model2_params_prior, model3_params_prior]\n",
    "simulators = [forward_model1, forward_model2, forward_model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultiModelTrainer(\n",
    "    network=evidential_net, \n",
    "    model_prior=model_prior, \n",
    "    priors=priors, \n",
    "    simulators=simulators, \n",
    "    loss=partial(log_loss, lambd=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online training\n",
    "Just a fast demo training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7127b4d34b294fc3804e5aa46de71bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 1:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af661490a674ff4b4d904abc7e2412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 2:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5bf9abd3244268bab53a3bc4e4100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 3:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2d016aff134c1f90b01c89504ca6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 4:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b902d2404e4dbfaae3d42601491ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 5:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b626660b20431d814480d910d76afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 6:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac80f184f1f34e78a4ebff78dd36b937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 7:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217a26c76f384652b07b75581aeba53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 8:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4175ea5e572a4893afc1e7a58adbea59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 9:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51828f143a2444d7804a046c773dca19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 10:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses = trainer.train_online(epochs=10, iterations_per_epoch=500, batch_size=32, n_obs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round-based training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and calibration checks\n",
    "Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
