{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed14fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"KERAS_BACKEND\"):\n",
    "    # Set to your favorite backend\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:28.594873177Z",
     "start_time": "2026-01-26T16:09:27.770643375Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Using backend 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import bayesflow as bf\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5967deb546fe554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:28.639765635Z",
     "start_time": "2026-01-26T16:09:28.595841682Z"
    }
   },
   "outputs": [],
   "source": [
    "def prior():\n",
    "    mu = np.random.standard_normal()\n",
    "    return {\"mu\": mu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830a1843e6b7ef8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:28.683500551Z",
     "start_time": "2026-01-26T16:09:28.640284427Z"
    }
   },
   "outputs": [],
   "source": [
    "def likelihood(mu, num_obs=10):\n",
    "    return {\"x\": mu + np.random.standard_normal((num_obs, 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d9e844dbfb369f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:28.729758204Z",
     "start_time": "2026-01-26T16:09:28.685855651Z"
    }
   },
   "outputs": [],
   "source": [
    "simulator = bf.make_simulator([prior, likelihood])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297f3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = bf.approximators.RatioApproximator.build_adapter(\n",
    "    inference_variables=[\"mu\"], \n",
    "    inference_conditions=[\"x\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2cfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_approximator = bf.approximators.RatioApproximator(\n",
    "    adapter=adapter,\n",
    "    classifier_network=bf.networks.MLP(),\n",
    "    summary_network=bf.networks.DeepSet(),\n",
    "    gamma=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8741113aa6acc422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:29.037287615Z",
     "start_time": "2026-01-26T16:09:28.982024858Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio_approximator.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeadc51ee5c5b44e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:09:57.487824337Z",
     "start_time": "2026-01-26T16:09:29.055585447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Building dataset from simulator instance of SequentialSimulator.\n",
      "INFO:bayesflow:Using 10 data loading workers.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - loss: 0.4806\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - loss: 0.4494\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - loss: 0.4478\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - loss: 0.4472\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 0.4466\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 0.4464\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - loss: 0.4460\n",
      "Epoch 8/10\n",
      "\u001b[1m 770/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.4458"
     ]
    }
   ],
   "source": [
    "history = ratio_approximator.fit(\n",
    "    epochs=10, \n",
    "    simulator=simulator,\n",
    "    num_batches=1000, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc903580",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plots.loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef548e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = simulator.sample(100)\n",
    "contrastive_sims = {\n",
    "    \"mu\": sims[\"mu\"][::-1],\n",
    "    \"x\": sims[\"x\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0835146",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ratio_positive = keras.ops.convert_to_numpy(ratio_approximator.log_ratio(sims))\n",
    "log_ratio_negative = keras.ops.convert_to_numpy(ratio_approximator.log_ratio(contrastive_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31895645",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "sns.histplot(log_ratio_positive, ax=ax, legend=\"Positive\", color=\"#00AA00\", alpha=0.5)\n",
    "sns.histplot(log_ratio_negative, ax=ax, legend=\"Positive\", color=\"#AA0000\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7eb4e",
   "metadata": {},
   "source": [
    "## Verify likelihood-evidence ratio against likelihood \n",
    "\n",
    "The log diff of likelihood and likelihood-evidence ratio should be constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(x, mu):\n",
    "    return np.sum(norm.logpdf(x, loc=mu, scale=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sims[\"mu\"]\n",
    "x_obs = sims[\"x\"][0]\n",
    "x_obs = np.repeat(x_obs[np.newaxis, :], mu.shape[0], axis=0)\n",
    "test_data = dict(x=x_obs, mu=mu)\n",
    "\n",
    "mu_broad = mu[:, np.newaxis, :]\n",
    "\n",
    "ll = log_likelihood(x_obs, mu_broad)\n",
    "lr = ratio_approximator.log_ratio(test_data)[:, np.newaxis]\n",
    "\n",
    "print(ll.shape)\n",
    "print(lr.shape)\n",
    "\n",
    "print(ll - lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d63bc4",
   "metadata": {},
   "source": [
    "## Verify likelihood-evidence ratio with PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed459d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "from pytensor.graph import Op, Apply\n",
    "import numpy as np\n",
    "\n",
    "class NRECLikelihoodOp(Op):\n",
    "    \"\"\"\n",
    "    Op for NRE-C: estimates p(x|theta) / p(x)\n",
    "    \"\"\"\n",
    "    def __init__(self, nrec_model, x_obs):\n",
    "        \"\"\"\n",
    "        nrec_model: your trained NRE-C classifier\n",
    "        x_obs: observed data\n",
    "        \"\"\"\n",
    "        self.model = nrec_model\n",
    "        self.x_obs = x_obs[np.newaxis, :]\n",
    "        \n",
    "    def make_node(self, mu):\n",
    "        mu = pt.as_tensor_variable(mu)\n",
    "        return Apply(self, [mu], [pt.dscalar()])\n",
    "    \n",
    "    def perform(self, node, inputs, outputs):\n",
    "        mu = inputs[0][np.newaxis, :]\n",
    "        \n",
    "        # NRE-C output: log(p(x|theta)/p(x))\n",
    "        # This is proportional to log p(x|theta) since p(x) is constant\n",
    "        data = dict(x = self.x_obs, mu = mu)\n",
    "        log_ratio = self.model.log_ratio(data)\n",
    "        \n",
    "        outputs[0][0] = np.asarray(log_ratio[0], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea20aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage in PyMC\n",
    "nrec_op = NRECLikelihoodOp(ratio_approximator, x_obs = sims[\"x\"][0])\n",
    "nrec_op.perform(inputs = sims[\"mu\"], node = None, outputs = [[np.empty(1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # prior\n",
    "    mu = pm.Normal('mu', mu=0, sigma=1, shape=1)\n",
    "    \n",
    "    # NRE-C likelihood\n",
    "    log_likelihood = nrec_op(mu)\n",
    "    pm.Potential('nrec_likelihood', log_likelihood)\n",
    "    \n",
    "    trace = pm.sample(2000, step=pm.Metropolis(), chains = 1, cores = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15589907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz\n",
    "arviz.plot_trace(trace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
