{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009b6adf",
   "metadata": {},
   "source": [
    "# Two Moons: Tackling Bimodal Posteriors\n",
    "\n",
    "_Authors: Lars Kühmichel, Marvin Schmitt, Valentin Pratz, Stefan T. Radev_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f88a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:36:22.149034Z",
     "start_time": "2024-10-24T08:36:20.807192Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "\n",
    "# For BayesFlow devs: this ensures that the latest dev version can be found\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import bayesflow as bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b26ba",
   "metadata": {},
   "source": [
    "## Simulator<a class=\"anchor\" id=\"simulator\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525ffd7",
   "metadata": {},
   "source": [
    "This example will demonstrate amortized estimation of a somewhat strange Bayesian model, whose posterior evaluated at the origin $x = (0, 0)$ of the \"data\" will resemble two crescent moons. The forward process is a noisy non-linear transformation on a 2D plane:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_1 &= -|\\theta_1 + \\theta_2|/\\sqrt{2} + r \\cos(\\alpha) + 0.25\\\\\n",
    "x_2 &= (-\\theta_1 + \\theta_2)/\\sqrt{2} + r\\sin{\\alpha}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "with $x = (x_1, x_2)$ playing the role of \"observables\" (data to be learned from), $\\alpha \\sim \\text{Uniform}(-\\pi/2, \\pi/2)$, and $r \\sim \\text{Normal}(0.1, 0.01)$ being latent variables creating noise in the data, and $\\theta = (\\theta_1, \\theta_2)$ being the parameters that we will later seek to infer from new $x$. We set their priors to\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_1, \\theta_2 \\sim \\text{Uniform}(-1, 1).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This model is typically used for benchmarking simulation-based inference (SBI) methods (see https://arxiv.org/pdf/2101.04653) and any method for amortized Bayesian inference should be capable of recovering the two moons posterior *without* using a gazillion of simulations. Note, that this is a considerably harder task than modeling the common unconditional two moons data set used often in the context of normalizing flows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf228e706a010",
   "metadata": {},
   "source": [
    "BayesFlow offers many ways to define your data generating process. Here, we use sequential functions to build a simulator object for online training. Within this composite simulator, each function has access to the outputs of the previous functions. This effectively allows you to define any generative graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f761b142a0e1da66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:36:22.160542Z",
     "start_time": "2024-10-24T08:36:22.155240Z"
    }
   },
   "outputs": [],
   "source": [
    "def theta_prior():\n",
    "    theta = np.random.uniform(-1, 1, 2)\n",
    "    return dict(theta=theta)\n",
    "\n",
    "def forward_model(theta):\n",
    "    alpha = np.random.uniform(-np.pi / 2, np.pi / 2)\n",
    "    r = np.random.normal(0.1, 0.01)\n",
    "    x1 = -np.abs(theta[0] + theta[1]) / np.sqrt(2) + r * np.cos(alpha) + 0.25\n",
    "    x2 = (-theta[0] + theta[1]) / np.sqrt(2) + r * np.sin(alpha)\n",
    "    return dict(x=np.array([x1, x2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cb773",
   "metadata": {},
   "source": [
    "Within the composite simulator, every simulator has access to the outputs of the previous simulators in the list. For example, the last simulator `forward_model` has access to the outputs of the three other simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89c861527c13b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:36:22.305265Z",
     "start_time": "2024-10-24T08:36:22.301546Z"
    }
   },
   "outputs": [],
   "source": [
    "simulator = bf.make_simulator([theta_prior, forward_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e287b2bccdad",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb5a1c9824246f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:39:46.950573Z",
     "start_time": "2024-09-23T14:39:46.948624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - loss: -0.0079 - loss/inference_loss: -0.0079 - val_loss: -0.3098 - val_loss/inference_loss: -0.3098\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -1.1417 - loss/inference_loss: -1.1417 - val_loss: -1.7498 - val_loss/inference_loss: -1.7498\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -1.9484 - loss/inference_loss: -1.9484 - val_loss: -1.4330 - val_loss/inference_loss: -1.4330\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -2.1626 - loss/inference_loss: -2.1626 - val_loss: -2.4202 - val_loss/inference_loss: -2.4202\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: -2.3003 - loss/inference_loss: -2.3003 - val_loss: -2.6998 - val_loss/inference_loss: -2.6998\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -2.4189 - loss/inference_loss: -2.4189 - val_loss: -2.6376 - val_loss/inference_loss: -2.6376\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: -2.6186 - loss/inference_loss: -2.6186 - val_loss: -2.8224 - val_loss/inference_loss: -2.8224\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -2.7313 - loss/inference_loss: -2.7313 - val_loss: -3.0671 - val_loss/inference_loss: -3.0671\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: -2.8883 - loss/inference_loss: -2.8883 - val_loss: -3.1921 - val_loss/inference_loss: -3.1921\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: -2.9451 - loss/inference_loss: -2.9451 - val_loss: -3.0162 - val_loss/inference_loss: -3.0162\n"
     ]
    }
   ],
   "source": [
    "workflow = bf.BasicWorkflow(simulator=simulator)\n",
    "\n",
    "history = workflow.fit_online(epochs=10, validation_data=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = workflow.plot_diagnostics(\n",
    "    test_data=300,\n",
    "    filter_names=[\"beta1\", \"beta2\"],\n",
    "    diagnostics = [\"recovery\", \"calibration\"]\n",
    ")\n",
    "\n",
    "metrics_dict = workflow.compute_diagnostics(\n",
    "    test_data=300,\n",
    "    diagnostics = [\"recovery\", \"calibration\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204e5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
